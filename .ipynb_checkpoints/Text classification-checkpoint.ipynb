{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95830095-3c37-4cf9-b28d-458e9c46c621",
   "metadata": {},
   "source": [
    "# 1. 数据加载和预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75c97025-ee09-4fb6-9699-63f2d1668102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总样本数: 30000\n",
      "类别分布: 体育    5000\n",
      "家居    5000\n",
      "房产    5000\n",
      "教育    5000\n",
      "科技    5000\n",
      "财经    5000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "texts = []  # 存储文本内容\n",
    "labels = []  # 存储标签\n",
    "\n",
    "with open(r'filtered_cnews.train.txt',  encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # 去除首尾空白字符（如换行符）\n",
    "        line = line.strip()\n",
    "        if line:  # 确保非空行\n",
    "            # 使用正则表达式提取标签和文本\n",
    "            match = re.match(r'^(\\S+)\\s+(.*)', line)\n",
    "            if match:\n",
    "                label, text = match.groups()\n",
    "                labels.append(label)\n",
    "                texts.append(text)\n",
    "\n",
    "# 查看数据基本信息\n",
    "print(f\"总样本数: {len(texts)}\")\n",
    "print(f\"类别分布: {pd.Series(labels).value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da4f67f-9e23-4913-800a-f3c5af2e0615",
   "metadata": {},
   "source": [
    "# 2. 数据划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85fb08a1-7751-49e8-a418-1e75e9ddb153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 24000\n",
      "验证集大小: 3000\n",
      "测试集大小: 3000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 划分训练集和临时集 (4000训练, 1000临时)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# 划分验证集和测试集 (各500)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(f\"训练集大小: {len(X_train)}\")\n",
    "print(f\"验证集大小: {len(X_val)}\")\n",
    "print(f\"测试集大小: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3118fd0f-0ba2-4255-9768-5745471fd456",
   "metadata": {},
   "source": [
    "# 3. 中文分词和特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51e45f9a-e6c4-41f2-810d-cb50e5f681cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "正在提取特征...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\APP\\anaconda3\\envs\\python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征维度: 5000\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def chinese_tokenizer(text):\n",
    "    return list(jieba.cut(text))\n",
    "# 使用TF-IDF提取特征\n",
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=chinese_tokenizer,\n",
    "    max_features=5000,  # 限制特征数量\n",
    "    ngram_range=(1, 2)  # 包含unigram和bigram\n",
    "    token_pattern=None\n",
    ")\n",
    "print(\"\\n正在提取特征...\")\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "print(f\"特征维度: {X_train_tfidf.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fed2a5-d621-41a3-81ca-3ce2bb090592",
   "metadata": {},
   "source": [
    "# 4. 模型训练和评估（函数）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b0485380-8fb3-4dfe-a100-b3b8632138a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def train_and_evaluate(model, model_name, X_train, y_train, X_val, y_val):\n",
    "    print(f\"\\n正在训练 {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # 在验证集上评估\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # 计算指标\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    report = classification_report(y_val, y_pred, output_dict=True)\n",
    "    \n",
    "    # 微平均和宏平均\n",
    "    micro_avg = report['micro avg']\n",
    "    macro_avg = report['macro avg']\n",
    "    \n",
    "    print(f\"\\n{model_name} 验证集准确率: {accuracy:.4f}\")\n",
    "    print(\"\\n分类报告:\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    \n",
    "    # 混淆矩阵\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=np.unique(labels), \n",
    "                yticklabels=np.unique(labels))\n",
    "    plt.title(f'{model_name} 混淆矩阵')\n",
    "    plt.xlabel('预测标签')\n",
    "    plt.ylabel('真实标签')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'name': model_name,\n",
    "        'accuracy': accuracy,\n",
    "        'micro_avg': micro_avg,\n",
    "        'macro_avg': macro_avg,\n",
    "        'confusion_matrix': cm\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66d4a0-180b-4d19-86ca-ed3c388a1c45",
   "metadata": {},
   "source": [
    "## 4.1 朴素贝叶斯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11100261-d0e6-4e03-b4b7-5e69210da4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "正在训练 朴素贝叶斯...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'micro avg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaive_bayes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MultinomialNB\n\u001b[0;32m      2\u001b[0m nb_model \u001b[38;5;241m=\u001b[39m MultinomialNB()\n\u001b[1;32m----> 3\u001b[0m nb_results \u001b[38;5;241m=\u001b[39m train_and_evaluate(nb_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m朴素贝叶斯\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      4\u001b[0m                                X_train_tfidf, y_train, \n\u001b[0;32m      5\u001b[0m                                X_val_tfidf, y_val)\n",
      "Cell \u001b[1;32mIn[33], line 18\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(model, model_name, X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[0;32m     15\u001b[0m report \u001b[38;5;241m=\u001b[39m classification_report(y_val, y_pred, output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 微平均和宏平均\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m micro_avg \u001b[38;5;241m=\u001b[39m report[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro avg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     19\u001b[0m macro_avg \u001b[38;5;241m=\u001b[39m report[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro avg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m 验证集准确率: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'micro avg'"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb_model = MultinomialNB()\n",
    "nb_results = train_and_evaluate(nb_model, \"朴素贝叶斯\", \n",
    "                               X_train_tfidf, y_train, \n",
    "                               X_val_tfidf, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87313a2-4919-48ab-a4e4-1af03c2f6e5a",
   "metadata": {},
   "source": [
    "## 4.2 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bd24bb-a14d-4bde-b60d-d4bcef276a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_results = train_and_evaluate(knn_model, \"KNN\", \n",
    "                                X_train_tfidf, y_train, \n",
    "                                X_val_tfidf, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd3e231-07a7-4bd3-890d-46c79464f265",
   "metadata": {},
   "source": [
    "## 4.3 GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2fc2e2-a746-4a1e-84df-6b51b4e1cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbdt_model = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    random_state=42\n",
    ")\n",
    "gbdt_results = train_and_evaluate(gbdt_model, \"GBDT\", \n",
    "                                 X_train_tfidf, y_train, \n",
    "                                 X_val_tfidf, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de540d11-5809-4ffe-b64e-33812b84dee0",
   "metadata": {},
   "source": [
    "# 5. 模型比较和选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94240732-6c8f-4871-a755-2fc77d356837",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [nb_results, knn_results, gbdt_results]\n",
    "\n",
    "print(\"\\n模型性能比较:\")\n",
    "comparison = pd.DataFrame({\n",
    "    '模型': [r['name'] for r in results],\n",
    "    '准确率': [r['accuracy'] for r in results],\n",
    "    '微平均F1': [r['micro_avg']['f1-score'] for r in results],\n",
    "    '宏平均F1': [r['macro_avg']['f1-score'] for r in results]\n",
    "})\n",
    "print(comparison)\n",
    "\n",
    "# 选择最佳模型\n",
    "best_model = gbdt_results['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ebdc98-1b83-4aaf-ab95-81cd23757dae",
   "metadata": {},
   "source": [
    "# 6. 测试集评估最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f9bd6c-933a-4493-ac57-abb8b2c8d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\n在测试集上评估最佳模型 (GBDT)...\")\n",
    "# y_test_pred = best_model.predict(X_test_tfidf)\n",
    "\n",
    "# print(\"\\n测试集分类报告:\")\n",
    "# print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# # 测试集混淆矩阵\n",
    "# cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', \n",
    "#             xticklabels=np.unique(labels), \n",
    "#             yticklabels=np.unique(labels))\n",
    "# plt.title('GBDT 测试集混淆矩阵')\n",
    "# plt.xlabel('预测标签')\n",
    "# plt.ylabel('真实标签')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3-Python312]",
   "language": "python",
   "name": "conda-env-anaconda3-Python312-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
